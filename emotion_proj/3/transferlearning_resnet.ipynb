{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4TeVmWyAISc-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np \n",
        "import pickle\n",
        "\n",
        "train_dataset_path = '/Users/soyoung/ml_project/emotion_proj/3/emo_train_dataset_0508.pkl' \n",
        "test_dataset_path = '/Users/soyoung/ml_project/emotion_proj/3/emo_test_dataset_0508.pkl'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xaEc5YAJJl9w"
      },
      "outputs": [],
      "source": [
        "#train_dataset, test_dataset pkl 파일 불러오기 \n",
        "with open(train_dataset_path, 'rb') as f:\n",
        "  train_dataset = pickle.load(f)\n",
        "\n",
        "with open(test_dataset_path, 'rb') as f:\n",
        "  test_dataset = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zj19x8TOJnhu"
      },
      "outputs": [],
      "source": [
        "#라벨값에 해당하는 숫자를 label_set에 저장.\n",
        "label_set = {'angry': 0,\n",
        " 'disgusted': 1,\n",
        " 'fearful': 2,\n",
        " 'happy': 3,\n",
        " 'neutral': 4,\n",
        " 'sad': 5,\n",
        " 'surprised': 6,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "B5Xu11xAJpK8"
      },
      "outputs": [],
      "source": [
        "#라벨값 숫자로 변환해서 train_data에 저장\n",
        "#img 차원값이 맨 앞으로 오도록 reshape (torch 포맷에 맞게)\n",
        "#이미지값 255로 나눠서 정규화 \n",
        "\n",
        "train_data = []\n",
        "for img, label in train_dataset:\n",
        "  train_data.append((img.reshape(1,48,48), label_set[label]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "L0pQscNNJpEk"
      },
      "outputs": [],
      "source": [
        "#라벨값 숫자로 변환해서 test_data에 저장\n",
        "#img 차원값이 맨 앞으로 오도록 reshape (torch 포맷에 맞게)\n",
        "#이미지값 255로 나눠서 정규화 \n",
        "\n",
        "test_data = []\n",
        "for img, label in test_dataset:\n",
        "  test_data.append((img.reshape(1,48,48), label_set[label]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SevcvV2BJrbd"
      },
      "outputs": [],
      "source": [
        "#자료형을 텐서로 변경해서 train, test에 저장. -> Data load 할 준비 완료\n",
        "train = [(torch.tensor(im, dtype=torch.float32),torch.tensor(label, dtype=torch.long)) for im,label in train_data]\n",
        "test = [(torch.tensor(im,dtype=torch.float32),torch.tensor(label, dtype=torch.long)) for im,label in test_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxRJErcsJvHa",
        "outputId": "e950e365-c84c-493c-9f57-9249f86655f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 48, 48])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train[0][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "P23T1O2vJwfT"
      },
      "outputs": [],
      "source": [
        "#Hyper parameter 설정 \n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 50\n",
        "LEARNING_RATE = 1e-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_LByXyzHJzVu"
      },
      "outputs": [],
      "source": [
        "# DataLoader \n",
        "train_loader = DataLoader(train, batch_size = BATCH_SIZE, shuffle=True) #drop_last = True\n",
        "test_loader = DataLoader(test, batch_size = BATCH_SIZE, shuffle=True) #drop_last = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBtl6IHZJ09w"
      },
      "source": [
        "# 전이학습\n",
        "- 이전에 training했던 모델을 가지고와서 조금만 training하면 내가 원하는데이터에 적용 가능할것이다\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tkNmLdLgK3ne"
      },
      "outputs": [],
      "source": [
        "from torchvision import models\n",
        "\n",
        "# pre trained model\n",
        "model = models.resnet18()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "P-3hC-h_fIWQ"
      },
      "outputs": [],
      "source": [
        "model.fc = nn.Linear(in_features=512, out_features=7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGhiVShqflzL",
        "outputId": "43759bb3-0ff7-421b-f90e-8dc336e8edf6"
      },
      "outputs": [],
      "source": [
        "model.conv1=nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "# model.bn1 = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "# model.relu = nn.ReLU(inplace=True)\n",
        "# model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FLfLJ-z3Ngm0"
      },
      "outputs": [],
      "source": [
        "from torch import optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "3EIUZYLFNl6j",
        "outputId": "e4329d14-4cfa-418a-b30e-4fc18f5a134d"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[14], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m pred \u001b[39m=\u001b[39m model(img)\n\u001b[1;32m     19\u001b[0m loss \u001b[39m=\u001b[39m criterion(pred, label)\n\u001b[0;32m---> 20\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     21\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     22\u001b[0m train_loss\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/machine/lib/python3.8/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/machine/lib/python3.8/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "from IPython.display import clear_output\n",
        "total = 0\n",
        "correct = 0\n",
        "##############\n",
        "total_acc = []\n",
        "best_acc = 0\n",
        "best_epoch = 0\n",
        "patience = 25\n",
        "counter = 0\n",
        "#학습진행\n",
        "losses = []\n",
        "for epoch in range(EPOCHS):\n",
        "  train_loss=[]\n",
        "  for img, label in train_loader:\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(img)\n",
        "    loss = criterion(pred, label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss.append(loss.item())\n",
        "  losses.append(np.array(train_loss).mean())\n",
        "#평가\n",
        "  test_loss= []\n",
        "  test_sources = []\n",
        "  with torch.no_grad():\n",
        "    for img, label in test_loader:\n",
        "      pred = model(img)\n",
        "      ###\n",
        "      # _, predicted = torch.max(pred.data, 1) #가장 높은 확률값으로 예측된 클래스\n",
        "      # total += label.size(0) #전체 데이터 개수 증가\n",
        "      # correct += (predicted == label.to(device)).sum().item() #예측값과 실제값이 일치하는 경우 개수 증가\n",
        "      ###\n",
        "      loss = criterion(pred, label)\n",
        "      test_loss.append(loss.item())\n",
        "      test_sources.append((img[pred.cpu().argmax(axis=1)!=label.cpu()],\n",
        "      label[pred.cpu().argmax(axis=1)!=label.cpu()],pred.cpu().argmax(axis=1)[pred.cpu().argmax(axis=1)!=label.cpu()]))\n",
        "  clear_output()\n",
        "  # 인식 잘 안된 부분의 시각화를 위해서 img, label, pred를 모아서 정리\n",
        "  imgs = [x[0] for x in test_sources]\n",
        "  imgs = torch.cat(imgs, axis=0)\n",
        "  labels = [x[1] for x in test_sources]\n",
        "  labels = torch.cat(labels, axis=0)\n",
        "  preds = [x[2] for x in test_sources]\n",
        "  preds = torch.cat(preds, axis=0)\n",
        "  # 정확도 계산을 위한 코드. 다양하게 다른 방법도 가능함\n",
        "  wrongs = [len(x[0]) for x in test_sources]\n",
        "  acc = round(100-(sum(wrongs)/100),2)\n",
        "  # acc = 100 * correct / total\n",
        "  # 정확도 추이를 보기 위하여 각 에폭에서의 정확도 정보 수집\n",
        "  total_acc.append(acc)\n",
        "  # 학습 진행 상황 출력\n",
        "  print(\"{}번째 train_loss : {} test_loss : {} Accuracy : {}%\".format(epoch, round(np.array(train_loss).mean(),2),round(np.array(test_loss).mean(),2),\n",
        "                                                                   acc))\n",
        "  if img.shape[0]<1:continue # 혹시 더이상 오분류 내용이 없으면 지나가도록 세팅\n",
        "  #가장 높은 정확도를 달성한 epoch 정보 저장\n",
        "  if acc > best_acc:\n",
        "    best_acc = acc\n",
        "    best_epoch = epoch\n",
        "    counter = 0\n",
        "    torch.save(model.state_dict(), 'best_model.pt')\n",
        "  else :\n",
        "    counter += 1\n",
        "    if counter >= patience:\n",
        "      print(\"Early stopping...\")\n",
        "      break\n",
        "  print(\"Best accuracy {}% achieved at epoch {}\".format(best_acc, best_epoch))\n",
        "  # 정확도 그래프 그리기\n",
        "  plt.plot(total_acc)\n",
        "  plt.show()\n",
        "  plt.title(\"label vs pred\")\n",
        "  label_list = ['angry','disgusted','fearful','happy','neutral','sad','surprised']\n",
        "  # 오분류 내용이 어떤건지 알기 위해 오분류 내용 4개 뽑아서 label과 pred 글자 넣어서 표시\n",
        "  for i in range(4):\n",
        "    plt.subplot(1,4,i+1)\n",
        "    label = label_list[labels[i].item()]\n",
        "    pred = label_list[preds[i].item()]    \n",
        "    plt.imshow(imgs[i][0], cmap='gray')    \n",
        "    plt.title(\"{} vs {}\".format(label,pred))\n",
        "    plt.axis('off')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGvv_aghRIMF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
