{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (28709, 2) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m/Users/soyoung/ml_project/emotion_proj/1/emo_test_dataset_real.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      7\u001b[0m     test_data \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(f)\n\u001b[0;32m----> 8\u001b[0m train_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray(train_data)\n\u001b[1;32m      9\u001b[0m test_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(test_data)\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (28709, 2) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "# train 데이터 로드\n",
    "with open('/Users/soyoung/ml_project/emotion_proj/1/emo_train_dataset_real.pkl', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "\n",
    "# test 데이터 로드\n",
    "with open('/Users/soyoung/ml_project/emotion_proj/1/emo_test_dataset_real.pkl', 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "\n",
    "train_data = np.array(train_data)\n",
    "test_data = np.array(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "28709\n",
      "<class 'tuple'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(train_data))\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(train_data[\u001b[39m0\u001b[39m]))\n\u001b[0;32m----> 5\u001b[0m \u001b[39mprint\u001b[39m(train_data[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mshape)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 데이터 확인\n",
    "print(type(train_data))\n",
    "print(len(train_data))\n",
    "print(type(train_data[0]))\n",
    "print(train_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data['data']\n",
    "        self.labels = data['label']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # 이미지를 0~1로 정규화합니다.\n",
    "        image = torch.FloatTensor(self.data[index]) / 255.\n",
    "        # 이미지와 라벨을 반환합니다.\n",
    "        return image.unsqueeze(0), self.labels[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# 데이터셋 생성\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_dataset \u001b[39m=\u001b[39m EmotionDataset(train_data)\n\u001b[1;32m      3\u001b[0m test_dataset \u001b[39m=\u001b[39m EmotionDataset(test_data)\n\u001b[1;32m      5\u001b[0m \u001b[39m# 데이터 로더 생성\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m, in \u001b[0;36mEmotionDataset.__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, data):\n\u001b[0;32m----> 3\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m      4\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "# 데이터셋 생성\n",
    "train_dataset = EmotionDataset(train_data)\n",
    "test_dataset = EmotionDataset(test_data)\n",
    "\n",
    "# 데이터 로더 생성\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.fc1 = nn.Linear(256 * 6 * 6, 512)\n",
    "        self.fc2 = nn.Linear(512, 7)  # 7개의 감정 라벨\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional Layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(-1, 256 * 6 * 6)\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CNN 모델이 정의되었으므로, 모델을 인스턴스화하고 손실 함수와 최적화 알고리즘을 설정합니다.\n",
    "\n",
    "# 모델 생성\n",
    "model = EmotionCNN()\n",
    "\n",
    "# 손실 함수와 최적화 알고리즘 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward Pass\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward Pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def evaluate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward Pass\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# 학습\n",
    "num_epochs = 50\n",
    "train_losses, train_accs = [], []\n",
    "val_losses, val_accs = [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(model, train_dataloader, criterion, optimizer)\n",
    "    val_loss, val_acc = evaluate(model, val_dataloader, criterion)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "# 테스트\n",
    "test_loss, test_acc = evaluate(model, test_dataloader, criterion)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axes[0].plot(train_losses, label='Train')\n",
    "axes[0].plot(val_losses, label='Val')\n",
    "axes[0].set_title('Loss')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(train_accs, label='Train')\n",
    "axes[1].plot(val_accs, label='Val')\n",
    "axes[1].set_title('Accuracy')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "torch.save(model.state_dict(), '/content/drive/MyDrive/emotion_proj/model/emotion_cnn.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        inputs = inputs.cpu().numpy().transpose((0, 2, 3, 1))\n",
    "        labels = labels.cpu().numpy()\n",
    "        preds = preds.cpu().numpy()\n",
    "        \n",
    "        for i in range(len(inputs)):\n",
    "            input_ = inputs[i]\n",
    "            label_ = labels[i]\n",
    "            pred_ = preds[i]\n",
    "            \n",
    "            # 이미지 출력\n",
    "            plt.imshow(input_)\n",
    "            plt.title(f'True: {label_to_emotion[label_]}, Pred: {label_to_emotion[pred_]}')\n",
    "            plt.axis('off')\n",
    "            plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
