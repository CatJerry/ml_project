{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터 로드\n",
    "with open('/Users/soyoung/ml_project/emotion_proj/2/emo_train.pkl', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "\n",
    "# test 데이터 로드\n",
    "with open('/Users/soyoung/ml_project/emotion_proj/2/emo_test.pkl', 'rb') as f:\n",
    "    test_data = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "28709\n",
      "<class 'dict'>\n",
      "{'image': array([[[ 60,  60,  60],\n",
      "        [ 41,  41,  41],\n",
      "        [ 29,  29,  29],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  1,   1,   1],\n",
      "        [  3,   3,   3]],\n",
      "\n",
      "       [[118, 118, 118],\n",
      "        [ 84,  84,  84],\n",
      "        [ 45,  45,  45],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  1,   1,   1]],\n",
      "\n",
      "       [[159, 159, 159],\n",
      "        [136, 136, 136],\n",
      "        [ 92,  92,  92],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[190, 190, 190],\n",
      "        [188, 188, 188],\n",
      "        [193, 193, 193],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  7,   7,   7],\n",
      "        [  7,   7,   7]],\n",
      "\n",
      "       [[188, 188, 188],\n",
      "        [185, 185, 185],\n",
      "        [189, 189, 189],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  5,   5,   5],\n",
      "        [ 11,  11,  11]],\n",
      "\n",
      "       [[188, 188, 188],\n",
      "        [184, 184, 184],\n",
      "        [184, 184, 184],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  3,   3,   3],\n",
      "        [ 12,  12,  12]]], dtype=uint8), 'label': 'happy'}\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "print(type(train_data))\n",
    "print(len(train_data))\n",
    "print(type(train_data[0]))\n",
    "print(train_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data['data']\n",
    "        self.labels = data['label']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # 이미지를 0~1로 정규화합니다.\n",
    "        image = torch.FloatTensor(self.data[index]) / 255.\n",
    "        # 이미지와 라벨을 반환합니다.\n",
    "        return image.unsqueeze(0), self.labels[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# 데이터셋 생성\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_dataset \u001b[39m=\u001b[39m EmotionDataset(train_data)\n\u001b[1;32m      3\u001b[0m test_dataset \u001b[39m=\u001b[39m EmotionDataset(test_data)\n\u001b[1;32m      5\u001b[0m \u001b[39m# 데이터 로더 생성\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m, in \u001b[0;36mEmotionDataset.__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, data):\n\u001b[0;32m----> 3\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m      4\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "# 데이터셋 생성\n",
    "train_dataset = EmotionDataset(train_data)\n",
    "test_dataset = EmotionDataset(test_data)\n",
    "\n",
    "# 데이터 로더 생성\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
