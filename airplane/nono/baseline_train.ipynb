{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import gc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(42) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_parquet(csv_path, save_name):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.to_parquet(f'./{save_name}.parquet')\n",
    "    del df\n",
    "    gc.collect()\n",
    "    print(save_name, 'Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_to_parquet('./train.csv', 'train')\n",
    "csv_to_parquet('./test.csv', 'test')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet('./train.parquet')\n",
    "sample_submission = pd.read_csv('sample_submission.csv', index_col = 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train)\n",
    "test_df = train_df[train_df['Delay'].isnull()]\n",
    "test_df.drop(columns='Delay',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_list = train_df[['Airline',\"Carrier_Code(IATA)\",\"Carrier_ID(DOT)\"]]\n",
    "airline_list.dropna(inplace=True)\n",
    "airline_list.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "302",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/downgrade/lib/python3.8/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/downgrade/lib/python3.8/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/downgrade/lib/python3.8/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2263\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2273\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 302",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n\u001b[1;32m     12\u001b[0m train_df \u001b[39m=\u001b[39m missing_values(train_df)\n\u001b[0;32m---> 13\u001b[0m test_df \u001b[39m=\u001b[39m missing_values(test_df)\n",
      "Cell \u001b[0;32mIn[20], line 6\u001b[0m, in \u001b[0;36mmissing_values\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m idx, value \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_values):\n\u001b[1;32m      5\u001b[0m     \u001b[39mif\u001b[39;00m value:\n\u001b[0;32m----> 6\u001b[0m         subset \u001b[39m=\u001b[39m airline_list[(airline_list[\u001b[39m\"\u001b[39m\u001b[39mAirline\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m df[\u001b[39m\"\u001b[39;49m\u001b[39mAirline\u001b[39;49m\u001b[39m\"\u001b[39;49m][idx]) \u001b[39m|\u001b[39m (airline_list[\u001b[39m\"\u001b[39m\u001b[39mCarrier_Code(IATA)\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m df[\u001b[39m\"\u001b[39m\u001b[39mCarrier_Code(IATA)\u001b[39m\u001b[39m\"\u001b[39m][idx])]\n\u001b[1;32m      7\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(subset) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m      8\u001b[0m             df\u001b[39m.\u001b[39mat[idx, \u001b[39m\"\u001b[39m\u001b[39mCarrier_ID(DOT)\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m subset[\u001b[39m\"\u001b[39m\u001b[39mCarrier_ID(DOT)\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/downgrade/lib/python3.8/site-packages/pandas/core/series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m    980\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 981\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m    983\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    984\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/downgrade/lib/python3.8/site-packages/pandas/core/series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1088\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1089\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1090\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/downgrade/lib/python3.8/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 302"
     ]
    }
   ],
   "source": [
    "# Carrier ID를 채울때 Airline 혹은 Carriercode가 같은 행의 데이터로 채운다.\n",
    "def missing_values(df):\n",
    "    missing_values = df[\"Carrier_ID(DOT)\"].isnull()\n",
    "    for idx, value in enumerate(missing_values):\n",
    "        if value:\n",
    "            subset = airline_list[(airline_list[\"Airline\"] == df[\"Airline\"][idx]) | (airline_list[\"Carrier_Code(IATA)\"] == df[\"Carrier_Code(IATA)\"][idx])]\n",
    "            if len(subset) > 0:\n",
    "                df.at[idx, \"Carrier_ID(DOT)\"] = subset[\"Carrier_ID(DOT)\"].iloc[0]\n",
    "                continue\n",
    "    return df\n",
    "\n",
    "train_df = missing_values(train_df)\n",
    "test_df = missing_values(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['date'] = train_df['Month'].astype(str)+'-'+train_df['Day_of_Month'].astype(str)\n",
    "train_df['date'] = pd.to_datetime(train_df['date'], format='%m-%d')\n",
    "test_df['date'] = test_df['Month'].astype(str)+'-'+test_df['Day_of_Month'].astype(str)\n",
    "test_df['date'] = pd.to_datetime(test_df['date'], format='%m-%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "downgrade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
