{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.mps.is_built()\n",
    "torch.backends.mps.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "PATH = '/Users/soyoung/ml_project/test_proj/따릉이/train.csv'\n",
    "data = pd.read_csv(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.pop('count')\n",
    "X = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier,TabNetRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X_train.to_numpy(), X_test.to_numpy(), y_train.to_numpy().reshape(-1,1), y_test.to_numpy().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.165e+03, 1.800e+01, 1.690e+01, ..., 5.000e-02, 7.300e+01,\n",
       "        5.700e+01],\n",
       "       [1.480e+03, 1.300e+01, 2.550e+01, ..., 5.700e-02, 3.700e+01,\n",
       "        2.200e+01],\n",
       "       [3.340e+02, 1.600e+01, 2.750e+01, ..., 6.700e-02, 4.500e+01,\n",
       "        2.700e+01],\n",
       "       ...,\n",
       "       [1.190e+03, 1.500e+01, 2.680e+01, ..., 6.700e-02, 8.600e+01,\n",
       "        4.600e+01],\n",
       "       [1.259e+03, 6.000e+00, 1.260e+01, ..., 4.000e-03, 3.200e+01,\n",
       "        2.000e+01],\n",
       "       [1.812e+03, 1.200e+01, 1.810e+01, ..., 4.600e-02, 3.400e+01,\n",
       "        1.700e+01]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 58.4933 | val_0_unsup_loss_numpy: 11.190170288085938|  0:00:01s\n",
      "epoch 1  | loss: 4.74015 | val_0_unsup_loss_numpy: 3.665410041809082|  0:00:03s\n",
      "epoch 2  | loss: 2.68062 | val_0_unsup_loss_numpy: 2.7881999015808105|  0:00:04s\n",
      "epoch 3  | loss: 2.4371  | val_0_unsup_loss_numpy: 2.2457900047302246|  0:00:05s\n",
      "epoch 4  | loss: 2.17924 | val_0_unsup_loss_numpy: 2.090590000152588|  0:00:07s\n",
      "epoch 5  | loss: 2.39277 | val_0_unsup_loss_numpy: 2.042479991912842|  0:00:08s\n",
      "epoch 6  | loss: 2.53653 | val_0_unsup_loss_numpy: 2.3040199279785156|  0:00:10s\n",
      "epoch 7  | loss: 2.54658 | val_0_unsup_loss_numpy: 2.962480068206787|  0:00:11s\n",
      "epoch 8  | loss: 2.31244 | val_0_unsup_loss_numpy: 2.021549940109253|  0:00:13s\n",
      "epoch 9  | loss: 1.97286 | val_0_unsup_loss_numpy: 1.879140019416809|  0:00:14s\n",
      "epoch 10 | loss: 2.10098 | val_0_unsup_loss_numpy: 1.9062199592590332|  0:00:16s\n",
      "epoch 11 | loss: 2.01885 | val_0_unsup_loss_numpy: 1.8871599435806274|  0:00:17s\n",
      "epoch 12 | loss: 2.29285 | val_0_unsup_loss_numpy: 1.8251399993896484|  0:00:19s\n",
      "epoch 13 | loss: 2.12982 | val_0_unsup_loss_numpy: 1.902959942817688|  0:00:20s\n",
      "epoch 14 | loss: 2.13645 | val_0_unsup_loss_numpy: 2.475480079650879|  0:00:22s\n",
      "epoch 15 | loss: 2.12633 | val_0_unsup_loss_numpy: 1.7939900159835815|  0:00:23s\n",
      "epoch 16 | loss: 1.94722 | val_0_unsup_loss_numpy: 1.8327800035476685|  0:00:25s\n",
      "epoch 17 | loss: 1.97259 | val_0_unsup_loss_numpy: 1.8851399421691895|  0:00:26s\n",
      "epoch 18 | loss: 1.96525 | val_0_unsup_loss_numpy: 2.1575400829315186|  0:00:28s\n",
      "epoch 19 | loss: 2.03128 | val_0_unsup_loss_numpy: 1.8081599473953247|  0:00:29s\n",
      "epoch 20 | loss: 1.90879 | val_0_unsup_loss_numpy: 1.8490099906921387|  0:00:31s\n",
      "epoch 21 | loss: 1.87974 | val_0_unsup_loss_numpy: 1.7896499633789062|  0:00:32s\n",
      "epoch 22 | loss: 1.88484 | val_0_unsup_loss_numpy: 2.5612399578094482|  0:00:34s\n",
      "epoch 23 | loss: 2.0703  | val_0_unsup_loss_numpy: 1.711069941520691|  0:00:35s\n",
      "epoch 24 | loss: 2.12673 | val_0_unsup_loss_numpy: 1.7470899820327759|  0:00:36s\n",
      "epoch 25 | loss: 1.90534 | val_0_unsup_loss_numpy: 3.272020101547241|  0:00:38s\n",
      "epoch 26 | loss: 2.23185 | val_0_unsup_loss_numpy: 2.0198700428009033|  0:00:39s\n",
      "epoch 27 | loss: 2.16809 | val_0_unsup_loss_numpy: 1.9763599634170532|  0:00:41s\n",
      "epoch 28 | loss: 2.17166 | val_0_unsup_loss_numpy: 1.849410057067871|  0:00:42s\n",
      "epoch 29 | loss: 2.01918 | val_0_unsup_loss_numpy: 2.1207499504089355|  0:00:43s\n",
      "epoch 30 | loss: 2.10445 | val_0_unsup_loss_numpy: 1.934790015220642|  0:00:45s\n",
      "epoch 31 | loss: 1.92743 | val_0_unsup_loss_numpy: 1.742319941520691|  0:00:46s\n",
      "epoch 32 | loss: 1.68146 | val_0_unsup_loss_numpy: 2.5251901149749756|  0:00:47s\n",
      "epoch 33 | loss: 1.99302 | val_0_unsup_loss_numpy: 2.2264299392700195|  0:00:49s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_unsup_loss_numpy = 1.711069941520691\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 27\u001b[0m\n\u001b[1;32m     10\u001b[0m unsupervised_model\u001b[39m.\u001b[39mfit(\n\u001b[1;32m     11\u001b[0m     X_train\u001b[39m=\u001b[39mX_train,\n\u001b[1;32m     12\u001b[0m     eval_set\u001b[39m=\u001b[39m[X_test],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     18\u001b[0m clf \u001b[39m=\u001b[39m TabNetClassifier(\n\u001b[1;32m     19\u001b[0m     optimizer_fn\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam,\n\u001b[1;32m     20\u001b[0m     optimizer_params\u001b[39m=\u001b[39m\u001b[39mdict\u001b[39m(lr\u001b[39m=\u001b[39m\u001b[39m2e-2\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     mask_type\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msparsemax\u001b[39m\u001b[39m'\u001b[39m \u001b[39m# This will be overwritten if using pretrain model\u001b[39;00m\n\u001b[1;32m     25\u001b[0m )\n\u001b[0;32m---> 27\u001b[0m clf\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     28\u001b[0m     X_train\u001b[39m=\u001b[39;49mX_train, y_train\u001b[39m=\u001b[39;49my_train,\n\u001b[1;32m     29\u001b[0m     eval_set\u001b[39m=\u001b[39;49m[(X_train, y_train), (X_test, y_test)],\n\u001b[1;32m     30\u001b[0m     eval_name\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mvalid\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     31\u001b[0m     eval_metric\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mauc\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     32\u001b[0m     from_unsupervised\u001b[39m=\u001b[39;49munsupervised_model\n\u001b[1;32m     33\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/downgrade/lib/python3.8/site-packages/pytorch_tabnet/abstract_model.py:203\u001b[0m, in \u001b[0;36mTabModel.fit\u001b[0;34m(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, from_unsupervised, warm_start, augmentations)\u001b[0m\n\u001b[1;32m    200\u001b[0m check_input(X_train)\n\u001b[1;32m    201\u001b[0m check_warm_start(warm_start, from_unsupervised)\n\u001b[0;32m--> 203\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate_fit_params(\n\u001b[1;32m    204\u001b[0m     X_train,\n\u001b[1;32m    205\u001b[0m     y_train,\n\u001b[1;32m    206\u001b[0m     eval_set,\n\u001b[1;32m    207\u001b[0m     weights,\n\u001b[1;32m    208\u001b[0m )\n\u001b[1;32m    210\u001b[0m \u001b[39m# Validate and reformat eval set depending on training data\u001b[39;00m\n\u001b[1;32m    211\u001b[0m eval_names, eval_set \u001b[39m=\u001b[39m validate_eval_set(eval_set, eval_name, X_train, y_train)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/downgrade/lib/python3.8/site-packages/pytorch_tabnet/tab_model.py:52\u001b[0m, in \u001b[0;36mTabNetClassifier.update_fit_params\u001b[0;34m(self, X_train, y_train, eval_set, weights)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_fit_params\u001b[39m(\n\u001b[1;32m     46\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     47\u001b[0m     X_train,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m     weights,\n\u001b[1;32m     51\u001b[0m ):\n\u001b[0;32m---> 52\u001b[0m     output_dim, train_labels \u001b[39m=\u001b[39m infer_output_dim(y_train)\n\u001b[1;32m     53\u001b[0m     \u001b[39mfor\u001b[39;00m X, y \u001b[39min\u001b[39;00m eval_set:\n\u001b[1;32m     54\u001b[0m         check_output_dim(train_labels, y)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/downgrade/lib/python3.8/site-packages/pytorch_tabnet/multiclass_utils.py:372\u001b[0m, in \u001b[0;36minfer_output_dim\u001b[0;34m(y_train)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minfer_output_dim\u001b[39m(y_train):\n\u001b[1;32m    357\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[39m    Infer output_dim from targets\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[39m        Sorted list of initial classes\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m     check_unique_type(y_train)\n\u001b[1;32m    373\u001b[0m     train_labels \u001b[39m=\u001b[39m unique_labels(y_train)\n\u001b[1;32m    374\u001b[0m     output_dim \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train_labels)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/downgrade/lib/python3.8/site-packages/pytorch_tabnet/multiclass_utils.py:349\u001b[0m, in \u001b[0;36mcheck_unique_type\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_unique_type\u001b[39m(y):\n\u001b[0;32m--> 349\u001b[0m     target_types \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mSeries(y)\u001b[39m.\u001b[39mmap(\u001b[39mtype\u001b[39m)\u001b[39m.\u001b[39munique()\n\u001b[1;32m    350\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(target_types) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    351\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    352\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mValues on the target must have the same type. Target has types \u001b[39m\u001b[39m{\u001b[39;00mtarget_types\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    353\u001b[0m         )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/downgrade/lib/python3.8/site-packages/pandas/core/series.py:470\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    468\u001b[0m         data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    469\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 470\u001b[0m     data \u001b[39m=\u001b[39m sanitize_array(data, index, dtype, copy)\n\u001b[1;32m    472\u001b[0m     manager \u001b[39m=\u001b[39m get_option(\u001b[39m\"\u001b[39m\u001b[39mmode.data_manager\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    473\u001b[0m     \u001b[39mif\u001b[39;00m manager \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mblock\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/downgrade/lib/python3.8/site-packages/pandas/core/construction.py:647\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure, allow_2d)\u001b[0m\n\u001b[1;32m    644\u001b[0m             subarr \u001b[39m=\u001b[39m cast(np\u001b[39m.\u001b[39mndarray, subarr)\n\u001b[1;32m    645\u001b[0m             subarr \u001b[39m=\u001b[39m maybe_infer_to_datetimelike(subarr)\n\u001b[0;32m--> 647\u001b[0m subarr \u001b[39m=\u001b[39m _sanitize_ndim(subarr, data, dtype, index, allow_2d\u001b[39m=\u001b[39;49mallow_2d)\n\u001b[1;32m    649\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(subarr, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m    650\u001b[0m     \u001b[39m# at this point we should have dtype be None or subarr.dtype == dtype\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     dtype \u001b[39m=\u001b[39m cast(np\u001b[39m.\u001b[39mdtype, dtype)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/downgrade/lib/python3.8/site-packages/pandas/core/construction.py:698\u001b[0m, in \u001b[0;36m_sanitize_ndim\u001b[0;34m(result, data, dtype, index, allow_2d)\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[39mif\u001b[39;00m allow_2d:\n\u001b[1;32m    697\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m--> 698\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mData must be 1-dimensional\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    699\u001b[0m \u001b[39mif\u001b[39;00m is_object_dtype(dtype) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, ExtensionDtype):\n\u001b[1;32m    700\u001b[0m     \u001b[39m# i.e. PandasDtype(\"O\")\u001b[39;00m\n\u001b[1;32m    702\u001b[0m     result \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39masarray_tuplesafe(data, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "\u001b[0;31mValueError\u001b[0m: Data must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "\n",
    "# TabNetPretrainer\n",
    "unsupervised_model = TabNetPretrainer(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    mask_type='entmax' # \"sparsemax\"\n",
    ")\n",
    "\n",
    "unsupervised_model.fit(\n",
    "    X_train=X_train,\n",
    "    eval_set=[X_test],\n",
    "    pretraining_ratio=0.8,\n",
    "    batch_size=16\n",
    "\n",
    ")\n",
    "\n",
    "clf = TabNetClassifier(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    scheduler_params={\"step_size\":10, # how to use learning rate scheduler\n",
    "                      \"gamma\":0.9},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "    mask_type='sparsemax' # This will be overwritten if using pretrain model\n",
    ")\n",
    "\n",
    "clf.fit(\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    eval_metric=['auc'],\n",
    "    from_unsupervised=unsupervised_model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "downgrade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
